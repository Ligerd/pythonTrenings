{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09f9a4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7af50b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitBySeparators(lineToSlit, reg):\n",
    "    return re.sub(reg, ' ', lineToSlit).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebd277e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addElemntToMap(mapOfWord, word, linecounter):\n",
    "    if word in mapOfWord:\n",
    "        mapOfWord[word].append(linecounter)\n",
    "    else:\n",
    "        mapOfWord[word] = [linecounter]\n",
    "    return mapOfWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc522819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analiseNotBaseCase(statOfWords, linecounter, wordToanalyse):\n",
    "    print(\"Analiz slowa \" , wordToanalyse )\n",
    "    word = None \n",
    "    for charIndex in range(len(wordToanalyse)):\n",
    "        char = wordToanalyse[charIndex]\n",
    "        if word ==None and char!='.':\n",
    "            print(\"Word is none\")\n",
    "            word = char\n",
    "        elif char.isdigit():\n",
    "            print(\"Char is digit\")\n",
    "            if word[-1].isdigit() or word[-1]=='.':\n",
    "                print(\"hellod\")\n",
    "                word = word + char\n",
    "            else:\n",
    "                statOfWords = addElemntToMap(statOfWords,word,linecounter)\n",
    "                word = char\n",
    "        elif char.isdigit() and word[-1].isalpha():\n",
    "            print(\"Char is digit and last of word is digit\")\n",
    "            statOfWords = addElemntToMap(statOfWords,word,linecounter)\n",
    "            word = char\n",
    "        elif char.isalpha() and word[-1].isdigit():\n",
    "            print(\"char is char and last of word is digit\")\n",
    "            statOfWords = addElemntToMap(statOfWords,word,linecounter)\n",
    "            word = char\n",
    "        elif char.isalpha() and word[-1].isalpha():\n",
    "            print(\"char is char and last of word is char\")\n",
    "            word = word+char\n",
    "        elif char == '.' and word!=None:\n",
    "            if wordToanalyse[charIndex-1].isdigit() and charIndex+1<len(wordToanalyse) and wordToanalyse[charIndex+1].isdigit() and not '.' in word:\n",
    "                word= word+char\n",
    "            elif word!=None:\n",
    "                statOfWords = addElemntToMap(statOfWords,word,linecounter)\n",
    "                word = None\n",
    "    if word !=None:\n",
    "        statOfWords = addElemntToMap(statOfWords,word,linecounter)\n",
    "    return statOfWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d03f6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeStats(filepath, encodingType):\n",
    "    outPutMap = {} \n",
    "    separatorsForWords = \"[\\\\\\\\!\\\"#$%&,\\'()\\*\\+\\-/:;\\?\\^_`{|}~]\"\n",
    "    numbersRegex = \"^([0-9]+\\d*([.]\\d+)?)$|^(-?0[.]\\d*[1-9]+)$|^0$|^0.0\"\n",
    "    try:\n",
    "        with open(filepath,\"r\",encoding=encodingType) as file:\n",
    "            linecounter=0\n",
    "            for line in file:\n",
    "                linecounter= linecounter+1\n",
    "                words = splitBySeparators(line,separatorsForWords)\n",
    "                for word in words:\n",
    "                    if bool(re.match(numbersRegex, word)) or word.isalpha():\n",
    "                        addElemntToMap(outPutMap,word,linecounter)\n",
    "                    else:    \n",
    "                        outPutMap = analiseNotBaseCase(outPutMap,linecounter,word)\n",
    "    except FileNotFoundError:\n",
    "        print('File not Found')\n",
    "    return outPutMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38a90592",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analiz slowa  występują.\n",
      "Word is none\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "Analiz slowa  ukośnikitp.\n",
      "Word is none\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "Analiz slowa  .\n",
      "Analiz slowa  całkowitej.\n",
      "Word is none\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "Analiz slowa  argumenty.\n",
      "Word is none\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "Analiz slowa  pliku.\n",
      "Word is none\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "Analiz slowa  występują.\n",
      "Word is none\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n",
      "char is char and last of word is char\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Napisz': [1],\n",
       " 'funkcję': [1],\n",
       " 'który': [1],\n",
       " 'wczytuje': [1],\n",
       " 'plik': [1],\n",
       " 'tekstowy': [1],\n",
       " 'i': [1, 1, 3],\n",
       " 'znajduje': [1],\n",
       " 'listę': [1],\n",
       " 'wyrazów': [1],\n",
       " 'liczb': [1],\n",
       " 'z': [1, 1, 2, 3],\n",
       " 'tego': [1],\n",
       " 'pliku': [1, 3, 3, 3],\n",
       " 'wraz': [1, 3],\n",
       " 'numerami': [1],\n",
       " 'linii': [1, 1, 3],\n",
       " 'w': [1, 3, 3],\n",
       " 'których': [1, 3],\n",
       " 'one': [1, 3],\n",
       " 'występują': [1, 3],\n",
       " 'Wyrazy': [1],\n",
       " 'mogą': [1],\n",
       " 'być': [1, 3, 3],\n",
       " 'oddzielone': [1],\n",
       " 'nie': [1],\n",
       " 'tylko': [1],\n",
       " 'spacjami': [1],\n",
       " 'ale': [1],\n",
       " 'też': [1],\n",
       " 'innymi': [1],\n",
       " 'znakami': [1],\n",
       " 'przecinek': [1],\n",
       " 'znak': [1, 1],\n",
       " 'zapytania': [1],\n",
       " 'nowej': [1],\n",
       " 'wykrzyknik': [1],\n",
       " 'plus': [1],\n",
       " 'minus': [1],\n",
       " 'gwiazdka': [1],\n",
       " 'ukośnikitp': [1],\n",
       " 'Liczby': [2],\n",
       " 'składają': [2],\n",
       " 'się': [2],\n",
       " 'cyfr': [2],\n",
       " 'a': [2, 3, 3],\n",
       " 'część': [2],\n",
       " 'ułamkowa': [2],\n",
       " 'jest': [2],\n",
       " 'oddzielona': [2],\n",
       " 'znakiem': [2],\n",
       " 'kropki': [2],\n",
       " 'od': [2],\n",
       " 'części': [2],\n",
       " 'całkowitej': [2],\n",
       " 'Funkcja': [3],\n",
       " 'powinna': [3, 3],\n",
       " 'mieć': [3],\n",
       " 'dwa': [3],\n",
       " 'argumenty': [3],\n",
       " 'Jednym': [3],\n",
       " 'nich': [3],\n",
       " 'nazwa': [3],\n",
       " 'ze': [3],\n",
       " 'ścieżką': [3],\n",
       " 'dostępu': [3],\n",
       " 'drugim': [3],\n",
       " 'sposób': [3],\n",
       " 'kodowania': [3],\n",
       " 'Wyniki': [3],\n",
       " 'działania': [3],\n",
       " 'funkcji': [3],\n",
       " 'powinny': [3],\n",
       " 'zwrócone': [3],\n",
       " 'jako': [3],\n",
       " 'słownik': [3],\n",
       " 'którego': [3],\n",
       " 'kluczami': [3],\n",
       " 'będą': [3],\n",
       " 'znalezione': [3],\n",
       " 'wyrazy': [3],\n",
       " 'liczby': [3],\n",
       " 'ich': [3],\n",
       " 'wartościami': [3],\n",
       " 'listy': [3],\n",
       " 'zawierające': [3],\n",
       " 'numery': [3]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "makeStats('task.txt','utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b7660c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if char not in separatorsForWords:\n",
    "        if word==\"\":\n",
    "                  word = word + char\n",
    "                        elif char.isdigit() and word[-1].isdigit():\n",
    "                            word = word + char\n",
    "                        elif not char.isdigit()  and word[-1].isdigit():\n",
    "                            outPutMap = addElemntToMap(outPutMap,word,linecounter)\n",
    "                            word = char\n",
    "                        elif not char.isdigit() and word[-1]=='.':                            \n",
    "                            outPutMap = addElemntToMap(outPutMap,word[:-1],linecounter)\n",
    "                            word = char\n",
    "                        elif char.isdigit() and word[-1]=='.':\n",
    "                            word = word + char\n",
    "                        elif char.isdigit() and not word[-1].isdigit():\n",
    "                            outPutMap = addElemntToMap(outPutMap,word,linecounter)\n",
    "                            word = char\n",
    "                        else:\n",
    "                            word = word + char\n",
    "                    else:\n",
    "                        if char =='.' and word!='' and '.' in word:\n",
    "                            if(word[-1]=='.'):\n",
    "                                outPutMap = addElemntToMap(outPutMap,word[:-1],linecounter)\n",
    "                                word = ''\n",
    "                            else:\n",
    "                                outPutMap = addElemntToMap(outPutMap,word,linecounter)\n",
    "                                word = ''\n",
    "                        elif char =='.' and word!='' and word[-1].isdigit():\n",
    "                            word = word + char\n",
    "                        else:\n",
    "                            if word!='':\n",
    "                                outPutMap = addElemntToMap(outPutMap,word,linecounter)\n",
    "                                word = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc52b3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateStat(filepath, encodingType):\n",
    "    outPutMap = {}\n",
    "    separatorsForWords = \"[!\\\"#$%&\\'()\\*\\+\\-/:;\\?\\^_`{|}~]\"\n",
    "    numbersRegex = \"^([-+]?[0-9]+\\d*([.]\\d+)?)$|^(-?0[.]\\d*[1-9]+)$|^0$|^0.0\"\n",
    "    try:\n",
    "        with open(filepath, \"r\", encoding=encodingType) as f:\n",
    "            linecount=0\n",
    "            for line in f:\n",
    "                linecount = linecount+1\n",
    "                wordsInLine = line.split()\n",
    "                for word in wordsInLine:\n",
    "                    if(checkIfNumber(word,numbersRegex)):\n",
    "                        if word in outPutMap:\n",
    "                            outPutMap[word].append(linecount)\n",
    "                        else:\n",
    "                            outPutMap[word] = [linecount]\n",
    "                    else:\n",
    "                        if bool(re.findall(separatorsForWords, word)):\n",
    "                            print(splitBySeparators(word, separatorsForWords))\n",
    "                            for splitWord in splitBySeparators(word, separatorsForWords):\n",
    "                                if splitWord in outPutMap:\n",
    "                                    print(\"dupa\")\n",
    "                                    outPutMap[splitWord].append(linecount)\n",
    "                                else:\n",
    "                                    print(\"dupa2\")\n",
    "                                    outPutMap[splitWord]=[linecount]\n",
    "                        else:\n",
    "                            print(\"dupa3\")\n",
    "                            if word in outPutMap:\n",
    "                                outPutMap[word].append(linecount)\n",
    "                            else:\n",
    "                                outPutMap[word]=[linecount]\n",
    "                            \n",
    "    except FileNotFoundError:\n",
    "        print('File not Found')\n",
    "    return outPutMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc31fb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "che"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dda47c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dupa3\n",
      "['25', '4']\n",
      "dupa2\n",
      "dupa2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'das': [1], '25': [1], '4': [1]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculateStat('test.txt','utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cd1a261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkIfNumber(input_string, reg):\n",
    "    return bool(re.match(reg, input_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d0df8d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkIfNumber(\"3.......\",\"^([-+]?[0-9]+\\d*([.]\\d+)?)$|^(-?0[.]\\d*[1-9]+)$|^0$|^0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "135fa931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitBySeparators(lineToSlit, reg):\n",
    "    print(reg)\n",
    "    return re.sub(reg, ' ', lineToSlit).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0779d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!\"#$%&'()\\*\\+\\-/:;\\?\\^_`{|}~]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['das', '25.4..']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitBySeparators(\"das -25.4..\",\"[!\\\"#$%&\\'()\\*\\+\\-/:;\\?\\^_`{|}~]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66841e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\\\"#$%&\\'()*+,-/:;<=>?@[\\\\]^_`{|}~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "39ac23f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool(re.findall(\"[!\\\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]\", \"-25,,,fg,-4..432.55j+46.)k-4.565\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "562b7660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['25', 'fg', '4', '432', '55j', '46', 'k', '4', '565']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitBySeparators(\"-25,,,fg,-4..432.55j+46.)k-4.565\",\"[!\\\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4432ec1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cc9f500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 13\n",
      "s 43\n",
      "4 34\n"
     ]
    }
   ],
   "source": [
    "exp = r'(\\w{1})(\\d+\\.?\\d+)'\n",
    "# f = open('test.txt','r')\n",
    "for line in open('test.txt','r'):\n",
    "    for letter,number in re.findall(exp, line):\n",
    "        print('{} {}'.format(letter, number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e682cbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import re\n",
    "\n",
    "Token = collections.namedtuple('Token', ['type', 'value', 'line', 'column'])\n",
    "\n",
    "class Scanner:\n",
    "\n",
    "  def __init__(self, input):\n",
    "    self.tokens = []\n",
    "    self.current_token_number = 0\n",
    "#     self.keywords = {'version:', 'services:', 'build:', 'ports:', 'image:', 'environment:', 'networks:', 'deploy:','mode:','replicas:','endpoint_mode:','volumes:'}\n",
    "    for token in self.tokenize(input):\n",
    "\t    self.tokens.append(token)\n",
    " \n",
    "  def tokenize(self, input_string):\n",
    "    token_specification = [\n",
    "        ('NUMBER',  r'\\d+(\\.\\d*)?'), # Integer or decimal number\n",
    "#         ('ASSIGN',  r':'),          # Assignment operator\n",
    "#         ('DASH', r'-'),\n",
    "        ('WORD',      r'[\\'-/:_A-Za-z0-9]+'),   # Identifiers\n",
    "#         ('QUOTE',   r'\"'),    \n",
    "        ('NEWLINE', r'\\n'),          # Line endings\n",
    "        ('SKIP',    r'[ \\t]'),       # Skip over spaces and tabs\n",
    "    ]\n",
    "    tok_regex = '|'.join('(?P<%s>%s)' % pair for pair in token_specification)\n",
    "    get_token = re.compile(tok_regex).match\n",
    "    line_number = 1\n",
    "    current_position = line_start = 0\n",
    "    match = get_token(input_string)\n",
    "    while match is not None:\n",
    "        type = match.lastgroup\n",
    "        if type == 'NEWLINE':\n",
    "            line_start = current_position\n",
    "            line_number += 1\n",
    "        elif type != 'SKIP':\n",
    "            value = match.group(type)\n",
    "#             if type == 'WORD':\n",
    "#                 type = 'value'\n",
    "            yield Token(type, value, line_number, match.start()-line_start)\n",
    "        current_position = match.end()\n",
    "        match = get_token(input_string, current_position)\n",
    "    if current_position != len(input_string):\n",
    "        raise RuntimeError('Error: Unexpected character %r on line %d' % \\\n",
    "                              (input_string[current_position], line_number))\n",
    "    yield Token('EOF', '', line_number, current_position-line_start)\n",
    "\n",
    "  def next_token(self):\n",
    "    self.current_token_number += 1\n",
    "    if self.current_token_number-1 < len(self.tokens):\n",
    "      return self.tokens[self.current_token_number-1]\n",
    "    else:\n",
    "      raise RuntimeError('Error: No more tokens')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "76da2d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = \"sad4, 42.4 sad asda sadasda.asdasdas dsadasd ads asdasda\"\n",
    "scanner = Scanner(input_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4e001189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Token(type='WORD', value='sad4,', line=1, column=0),\n",
       " Token(type='NUMBER', value='42.4', line=1, column=6),\n",
       " Token(type='WORD', value='sad', line=1, column=11),\n",
       " Token(type='WORD', value='asda', line=1, column=15),\n",
       " Token(type='WORD', value='sadasda.asdasdas', line=1, column=20),\n",
       " Token(type='WORD', value='dsadasd', line=1, column=37),\n",
       " Token(type='WORD', value='ads', line=1, column=45),\n",
       " Token(type='WORD', value='asdasda', line=1, column=49),\n",
       " Token(type='EOF', value='', line=1, column=56)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scanner.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7ece2ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Token(type='WORD', value='sad4,', line=1, column=0)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scanner.next_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2cacfea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Token(type='NUMBER', value='42.4', line=1, column=6)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scanner.next_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dabd78ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 647\n",
      "[56, 647]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "s=input()\n",
    "nums= re.findall(r'\\d+',s)\n",
    "nums=[int(i)for i in nums]\n",
    "print(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f670ef11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', ',', 'bar', '@', 'candy', '*', 'ice', '%', 'cream']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "a = \"foo,bar@candy*ice%cream\"\n",
    "re.split('([^a-zA-Z0-9])',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec8a8d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
